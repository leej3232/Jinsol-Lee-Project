{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VZl3hZtm68J"
   },
   "source": [
    "# 0) ì„¤ì¹˜ & ê¸°ë³¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvGeVUWAmTJi"
   },
   "outputs": [],
   "source": [
    "# (Colab í•„ìš” ì‹œ) ì‹œìŠ¤í…œ/ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!apt-get -qq install pv\n",
    "!pip -q install rasterio matplotlib numpy\n",
    "!pip install transformers torch rasterio\n",
    "!pip install opencv-python-headless\n",
    "!pip install --upgrade transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGqzLPpQmSl7"
   },
   "outputs": [],
   "source": [
    "# ---- Imports & ì „ì—­ ì˜µì…˜ ----\n",
    "import os, re, time, tarfile, subprocess, shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import rasterio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor\n",
    "\n",
    "# Drive ë§ˆìš´íŠ¸: ì²´í¬í¬ì¸íŠ¸/ì•„ì›ƒí’‹ ì €ì¥ìš©\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ì„±ëŠ¥ ìµœì í™”: cudnn ì»¤ë„ íƒìƒ‰ í—ˆìš©, matmul ì •ë°€ë„ ì™„í™”(ì§€ì› ì‹œ)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"medium\")\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nUdMa6bnCtW"
   },
   "source": [
    "# 1) ë°ì´í„° ì••ì¶• í•´ì œ íŒŒì´í”„ë¼ì¸\n",
    "ì—¬ëŸ¬ ê°œë¡œ ë¶„í• ëœ *.zip.part*ë¥¼ ì •ë ¬ â†’ ë³‘í•© â†’ unzipí•˜ëŠ” ìë™í™”.\n",
    "\n",
    "subprocess.run() ìœ¼ë¡œ ì…¸ í˜¸ì¶œì„ ì•ˆì „í•˜ê²Œ ìˆ˜í–‰.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YrjkMJC5mSbJ"
   },
   "outputs": [],
   "source": [
    "def run_cmd(cmd_list):\n",
    "    \"\"\"ì™¸ë¶€ ëª…ë ¹ ì‹¤í–‰(ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ)\"\"\"\n",
    "    subprocess.run(cmd_list, check=True)\n",
    "\n",
    "def final_extract_and_rename_pythonic(tar_path, output_folder):\n",
    "    \"\"\"\n",
    "    ì…ë ¥: .tar ê²½ë¡œ / ì¶œë ¥: ì••ì¶• í•´ì œëœ íŒŒì¼(ì´ë¯¸ì§€ ë˜ëŠ” ë¼ë²¨)\n",
    "    ë‹¨ê³„:\n",
    "      1) tar í’€ê¸°\n",
    "      2) ë‚´ë¶€ì˜ *.zip.part* ì¡´ì¬ ì‹œ ìˆœì„œëŒ€ë¡œ rename\n",
    "      3) partë“¤ì„ ì´ì–´ë¶™ì—¬ í•˜ë‚˜ì˜ zipìœ¼ë¡œ ë³‘í•©\n",
    "      4) unzip ì§„í–‰\n",
    "      5) ì„ì‹œ ë””ë ‰í„°ë¦¬ ì •ë¦¬\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(tar_path)\n",
    "    print(f\"ğŸš€ Processing {base_name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ì„ì‹œ ë””ë ‰í„°ë¦¬: íŒŒì¼ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ tar íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œ ìƒì„±\n",
    "    temp_dir = f\"/content/temp_{os.path.splitext(base_name)[0]}\"\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 1) .tar í’€ê¸°\n",
    "    print(f\"[{base_name}] Step 1: Un-tarring...\")\n",
    "    try:\n",
    "        with tarfile.open(tar_path, 'r') as tar:\n",
    "            tar.extractall(path=temp_dir)\n",
    "    except tarfile.TarError as e:\n",
    "        print(f\"[{base_name}] tar extracting failed: {e}\")\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        return\n",
    "    print(f\"[{base_name}] Un-tarring complete.\")\n",
    "\n",
    "    # 2) .zip.part* ì°¾ê¸° (ì—†ëŠ” ê²½ìš° ë‹¨ì¼ zip ì—¬ë¶€ í™•ì¸)\n",
    "    print(f\"[{base_name}] Step 2: Finding and renaming part files...\")\n",
    "    part_files = [os.path.join(root, f)\n",
    "                  for root, _, files in os.walk(temp_dir)\n",
    "                  for f in files if '.zip.part' in f]\n",
    "\n",
    "    def get_part_number(filepath):\n",
    "        \"\"\"íŒŒì¼ëª… ëì˜ .partNN ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ì •ë ¬ í‚¤ë¡œ ì‚¬ìš©\"\"\"\n",
    "        try:\n",
    "            return int(re.search(r'\\.part(\\d+)$', os.path.basename(filepath)).group(1))\n",
    "        except (AttributeError, ValueError):\n",
    "            return -1\n",
    "    part_files.sort(key=get_part_number)\n",
    "\n",
    "    if not part_files:\n",
    "        # partê°€ ì—†ìœ¼ë©´ ë‹¨ì¼ zipë§Œ ì¡´ì¬í•  ìˆ˜ ìˆìŒ\n",
    "        zip_files = [os.path.join(root, f)\n",
    "                     for root, _, files in os.walk(temp_dir)\n",
    "                     for f in files if f.endswith('.zip')]\n",
    "        if zip_files:\n",
    "            print(f\"[{base_name}] Unzipping single zip...\")\n",
    "            run_cmd([\"unzip\", \"-o\", \"-q\", zip_files[0], \"-d\", output_folder])\n",
    "        else:\n",
    "            print(f\"[{base_name}] No zip files to extract.\")\n",
    "    else:\n",
    "        # partê°€ ìˆìœ¼ë©´: ì¼ê´€ëœ ì´ë¦„ìœ¼ë¡œ ì¬ëª…ëª… í›„ zip ë³‘í•©\n",
    "        zip_file_basename = \"\"\n",
    "        renamed_paths = []\n",
    "        match = re.match(r'(.+\\.zip)\\.part.*', os.path.basename(part_files[0]))\n",
    "        if match:\n",
    "            zip_file_basename = match.group(1)\n",
    "            dir_name = os.path.dirname(part_files[0])\n",
    "            # .part00, .part01 ... ë¡œ ê°•ì œ ì •ë ¬(ëˆ„ë½Â·ìˆœì„œí‹€ë¦¼ ë°©ì§€)\n",
    "            for i, old_path in enumerate(tqdm(part_files, desc=f\"[{base_name}] Renaming\", leave=False)):\n",
    "                new_path = os.path.join(dir_name, f\"{zip_file_basename}.part{i:02d}\")\n",
    "                os.rename(old_path, new_path)\n",
    "                renamed_paths.append(new_path)\n",
    "\n",
    "        if not renamed_paths:\n",
    "            print(f\"[{base_name}] âŒ Error: Renaming failed.\")\n",
    "        else:\n",
    "            print(f\"[{base_name}] Renamed {len(part_files)} files.\")\n",
    "            # 3) íŒŒíŠ¸ë¥¼ ì°¨ë¡€ëŒ€ë¡œ ì´ì–´ë¶™ì—¬ ë‹¨ì¼ zip ìƒì„±\n",
    "            print(f\"[{base_name}] Step 3: Combining and Unzipping...\")\n",
    "            parts_directory = os.path.dirname(renamed_paths[0])\n",
    "            combined_zip_path = os.path.join(parts_directory, zip_file_basename)\n",
    "            with open(combined_zip_path, \"wb\") as w:\n",
    "                for p in sorted(renamed_paths):\n",
    "                    with open(p, \"rb\") as r:\n",
    "                        shutil.copyfileobj(r, w)\n",
    "            # 4) unzip ì‹¤í–‰\n",
    "            run_cmd([\"unzip\", \"-o\", \"-q\", combined_zip_path, \"-d\", output_folder])\n",
    "\n",
    "    # 5) ì„ì‹œ íŒŒì¼ ì •ë¦¬(ìŠ¤í† ë¦¬ì§€ ì ˆì•½)\n",
    "    print(f\"[{base_name}] Step 4: Cleaning up temporary files...\")\n",
    "    shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"âœ… Done with {base_name} in {end_time - start_time:.2f} seconds.\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# (í•„ìš”ì‹œ) ë³‘ë ¬ë¡œ í˜¸ì¶œ\n",
    "import concurrent.futures\n",
    "tasks = [\n",
    "     (\"/content/drive/MyDrive/VS_SN.tar\", \"/content/vs_sn\"),\n",
    "     (\"/content/drive/MyDrive/TL_SN.tar\", \"/content/tl_sn\"),\n",
    "     (\"/content/drive/MyDrive/VL_SN.tar\", \"/content/vl_sn\"),\n",
    "     (\"/content/drive/MyDrive/TS_SN.tar\", \"/content/ts_sn\")\n",
    " ]\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "     executor.map(lambda p: final_extract_and_rename_pythonic(*p), tasks)\n",
    "print(\"\\nğŸ‰ All datasets processing finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0t9PkLZhnwbO"
   },
   "source": [
    "# 2) ë°ì´í„°ì…‹ & ì „ì²˜ë¦¬\n",
    "\n",
    "ì´ë¯¸ì§€: (C,H,W) uint16 â†’ /256ìœ¼ë¡œ uint8 ìŠ¤ì¼€ì¼ â†’ (H,W,C)ë¡œ ë³€í™˜ í›„ AREA ë¦¬ì‚¬ì´ì¦ˆ â†’ (C,H,W) ë³µê·€ â†’ float32/255ë¡œ [0,1] ì •ê·œí™”\n",
    "\n",
    "\n",
    "ë¼ë²¨: (H,W) â†’ NEAREST ë¦¬ì‚¬ì´ì¦ˆ â†’ 90â†’1 ì´ì§„í™”(ê·¸ ì™¸ 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXgfwmktmSIO"
   },
   "outputs": [],
   "source": [
    "class SegformerDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, image_processor):\n",
    "        # ìˆ¨ê¹€íŒŒì¼ ì œì™¸ + ì´ë¦„ ì •ë ¬(ì´ë¯¸ì§€Â·ë¼ë²¨ 1:1 ë§¤ì¹­ì„ ìœ„í•´ ì¤‘ìš”)\n",
    "        self.image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if not f.startswith('.')])\n",
    "        self.label_paths = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if not f.startswith('.')])\n",
    "\n",
    "        # ê°œìˆ˜ ë¶ˆì¼ì¹˜ ë°©ì§€(ì´ˆê¸°ì— ì¡ì•„ì•¼ ë””ë²„ê·¸ ì‰¬ì›€)\n",
    "        assert len(self.image_paths) == len(self.label_paths), \\\n",
    "            f\"Count mismatch: {len(self.image_paths)} images vs {len(self.label_paths)} labels\"\n",
    "\n",
    "        # (ì„ íƒ) íŒŒì¼ëª… ìŠ¤í…œ ì¼ì¹˜ ì—¬ë¶€ë¥¼ ì—„ê²© ê²€ì‚¬(ë¼ë²¨-ì´ë¯¸ì§€ ë’¤ì„ì„ ë°©ì§€)\n",
    "        for ip, lp in zip(self.image_paths, self.label_paths):\n",
    "            if os.path.splitext(os.path.basename(ip))[0] != os.path.splitext(os.path.basename(lp))[0]:\n",
    "                raise ValueError(f\"Name mismatch: {os.path.basename(ip)} vs {os.path.basename(lp)}\")\n",
    "\n",
    "        self.image_processor = image_processor\n",
    "        # SegFormer ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©(height==width ê°€ì •)\n",
    "        self.target_size = self.image_processor.size['height']\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # --- ì´ë¯¸ì§€ ì½ê¸° (uint16) ---\n",
    "        with rasterio.open(self.image_paths[idx]) as src:\n",
    "            image = src.read()                     # (C,H,W), uint16\n",
    "\n",
    "        # uint16 â†’ uint8 ìŠ¤ì¼€ì¼ ë‹¤ìš´: Sentinel-2 ëŒ€ì—­ì„ ê°„ê²°íˆ 8ë¹„íŠ¸ë¡œ\n",
    "        image_rescaled = (image / 256).astype(np.uint8)\n",
    "\n",
    "        # ë¦¬ì‚¬ì´ì¦ˆë¥¼ ìœ„í•´ (H,W,C)ë¡œ ì „ì¹˜\n",
    "        image_hwc = np.transpose(image_rescaled, (1, 2, 0))\n",
    "        resized_image = cv2.resize(\n",
    "            image_hwc, (self.target_size, self.target_size),\n",
    "            interpolation=cv2.INTER_AREA           # ì—°ì†í†¤ ì´ë¯¸ì§€ì— ì í•©\n",
    "        )\n",
    "\n",
    "        # ëª¨ë¸ ì…ë ¥ í˜•íƒœ(C,H,W)ë¡œ ë³µê·€ í›„ [0,1] ì •ê·œí™” (float32)\n",
    "        image_chw = np.transpose(resized_image, (2, 0, 1))\n",
    "        pixel_values = torch.from_numpy(image_chw).float() / 255.0\n",
    "\n",
    "        # --- ë¼ë²¨ ì½ê¸° & ì´ì§„í™” ---\n",
    "        with rasterio.open(self.label_paths[idx]) as src:\n",
    "            label = src.read(1)                    # (H,W)\n",
    "\n",
    "        # í´ë˜ìŠ¤ ê²½ê³„ ë³´ì¡´ì„ ìœ„í•´ ìµœê·¼ì ‘ ë³´ê°„\n",
    "        resized_label = cv2.resize(\n",
    "            label, (self.target_size, self.target_size),\n",
    "            interpolation=cv2.INTER_NEAREST\n",
    "        )\n",
    "\n",
    "        # ê°’ 90ë§Œ íƒ€ê¹ƒ(1), ë‚˜ë¨¸ì§€ 0\n",
    "        new_label = np.zeros_like(resized_label, dtype=np.int64)\n",
    "        new_label[resized_label == 90] = 1\n",
    "\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": torch.from_numpy(new_label).long()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CREFZSQ8n9Q3"
   },
   "source": [
    "# 3) ëª¨ë¸ ë¹Œë” â€” SegFormer-B1 (4ì±„ë„ ì…ë ¥ ì§€ì›)\n",
    "HuggingFace SegformerForSemanticSegmentation ë¡œë“œ\n",
    "\n",
    "ì²« patch embedding conv(in_channels: 3)ë¥¼ 4ì±„ë„ë¡œ êµì²´ + ê°€ì¤‘ì¹˜ ì´ì‹\n",
    "\n",
    "4ë²ˆì§¸ ì±„ë„ì€ ê¸°ì¡´ 3ì±„ë„ í‰ê· ìœ¼ë¡œ ì´ˆê¸°í™”(ì•ˆì •ì  ì‹œì‘)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hIycSbPn-L4"
   },
   "outputs": [],
   "source": [
    "def build_segformer_4ch(num_classes=2, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "        \"nvidia/segformer-b1-finetuned-ade-512-512\",\n",
    "        num_labels=num_classes,                    # ì¶œë ¥ í´ë˜ìŠ¤(ë°°ê²½/ì‚°ì—…ë‹¨ì§€)\n",
    "        ignore_mismatched_sizes=True               # í—¤ë“œ í¬ê¸° ë¶ˆì¼ì¹˜ í—ˆìš©\n",
    "    )\n",
    "\n",
    "    # --- 3â†’4ì±„ë„ conv êµì²´ ---\n",
    "    original_conv = model.segformer.encoder.patch_embeddings[0].proj\n",
    "    old_weights = original_conv.weight.clone()     # (out, 3, k, k)\n",
    "    new_conv = nn.Conv2d(\n",
    "        4, original_conv.out_channels,\n",
    "        kernel_size=original_conv.kernel_size,\n",
    "        stride=original_conv.stride,\n",
    "        padding=original_conv.padding\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        # ê¸°ì¡´ 3ì±„ë„ì€ ê·¸ëŒ€ë¡œ ë³µì‚¬\n",
    "        new_conv.weight[:, :3, :, :] = old_weights\n",
    "        # 4ë²ˆì§¸ ì±„ë„ì€ 3ì±„ë„ í‰ê· ìœ¼ë¡œ ì´ˆê¸°í™”(ë³µì œ ëŒ€ë¹„ ì•ˆì •ì )\n",
    "        new_conv.weight[:, 3:, :, :] = old_weights.mean(1, keepdim=True)\n",
    "        if original_conv.bias is not None:\n",
    "            new_conv.bias = nn.Parameter(original_conv.bias.clone())\n",
    "    model.segformer.encoder.patch_embeddings[0].proj = new_conv\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # (ì„ íƒ) ì»¤ë„ í“¨ì „/ê·¸ë˜í”„ ìµœì í™”: ì§€ì›ë˜ì§€ ì•Šìœ¼ë©´ ë¬´ì‹œ\n",
    "    try:\n",
    "        model = torch.compile(model)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaf-KGGtoGkk"
   },
   "source": [
    "# 4) í‰ê°€ í•¨ìˆ˜\n",
    "4-1. ê³µì‹ â€” sigmoid(z1 - z0) ê¸°ë°˜ Accuracy / IoU@0.5\n",
    "\n",
    "2-í´ë˜ìŠ¤ ë¡œì§“ z0,z1ì—ì„œ ì°¨ì´ë¥¼ ì·¨í•´ ì•ˆì •ì ì¸ í™•ë¥  ê³„ì‚°\n",
    "\n",
    "í™•ë¥  0.5 ì„ê³„ê°’ìœ¼ë¡œ ì´ì§„ ë§ˆìŠ¤í¬ ìƒì„± â†’ IoU ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lfVjaL8roNYF"
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def evaluate_sigmoid(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    ê³µì‹ í‰ê°€:\n",
    "      - logits -> bilinear ì—…ìƒ˜í”Œë§(H,W ì •í•©)\n",
    "      - z1 - z0 -> sigmoid -> prob1\n",
    "      - pred = (prob1 > 0.5)\n",
    "      - Accuracy, IoU(í´ë˜ìŠ¤=1 ê¸°ì¤€) ë°˜í™˜\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_pixels  = 0\n",
    "    total_inter   = 0\n",
    "    total_union   = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"[Evaluation]\"):\n",
    "        pv = batch[\"pixel_values\"].to(device, non_blocking=True)   # (B,4,H,W)\n",
    "        gt = batch[\"labels\"].to(device, non_blocking=True)         # (B,H,W), 0/1\n",
    "\n",
    "        out = model(pixel_values=pv)                               # logits: (B,2,h,w)\n",
    "        logits = F.interpolate(out.logits, size=gt.shape[-2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        logit_diff = logits[:, 1] - logits[:, 0]                   # (B,H,W)\n",
    "        prob1 = torch.sigmoid(logit_diff)                          # (B,H,W), target í™•ë¥ \n",
    "        pred  = (prob1 > 0.5).long()                               # (B,H,W), 0/1\n",
    "\n",
    "        total_correct += (pred == gt).sum().item()\n",
    "        total_pixels  += gt.numel()\n",
    "\n",
    "        inter = ((pred == 1) & (gt == 1)).sum().item()\n",
    "        union = ((pred == 1) | (gt == 1)).sum().item()\n",
    "        total_inter += inter\n",
    "        total_union += union\n",
    "\n",
    "    acc = total_correct / total_pixels\n",
    "    iou = (total_inter / total_union) if total_union > 0 else 0.0\n",
    "    return acc, iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2J3AoR1BoQF2"
   },
   "source": [
    "4-2. ì°¸ê³  â€” softmax-argmax ê¸°ë°˜ mIoU/PixelAcc\n",
    "\n",
    "í´ë˜ìŠ¤ë³„ IoU í‰ê· (mIoU)ì„ ê³„ì‚°í•  ë•Œ ìœ ìš©(ë³´ê³ ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxdpfDJJoS4G"
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def evaluate_argmax_miou(model, dataloader, device, num_classes=2):\n",
    "    \"\"\"\n",
    "    ì°¸ê³  ì§€í‘œ:\n",
    "      - softmax/argmaxë¡œ í´ë˜ìŠ¤ ì˜ˆì¸¡(0/1)\n",
    "      - í´ë˜ìŠ¤ë³„ IoU í‰ê· (mIoU) + Pixel Accuracy ë°˜í™˜\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    for batch in tqdm(dataloader, desc=\"[Eval-argmax]\"):\n",
    "        pv = batch[\"pixel_values\"].to(device, non_blocking=True)\n",
    "        gt = batch[\"labels\"].to(device, non_blocking=True)\n",
    "        out = model(pixel_values=pv)\n",
    "        logits = F.interpolate(out.logits, size=gt.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        preds = torch.argmax(logits, dim=1)         # (B,H,W)\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(gt.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    iou_per_class = []\n",
    "    for cls in range(num_classes):\n",
    "        inter = np.sum((all_preds == cls) & (all_labels == cls))\n",
    "        uni   = np.sum((all_preds == cls) | (all_labels == cls))\n",
    "        if uni > 0:\n",
    "            iou_per_class.append(inter / uni)\n",
    "\n",
    "    macro_miou = float(np.mean(iou_per_class)) if iou_per_class else 0.0\n",
    "    micro_acc  = float(np.sum(all_preds == all_labels) / all_labels.size)\n",
    "    return macro_miou, micro_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RyAtarYoUrb"
   },
   "source": [
    "# 5) ì„¤ì •ê°’ & ê²½ë¡œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRT7Gcnfob54"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# í•™ìŠµ/í‰ê°€ ìŠ¤ìœ„ì¹˜: í•™ìŠµì€ True, ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ë¡œ í‰ê°€ë§Œ í•  ë• False\n",
    "TRAIN = True\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "# ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ(Drive ì €ì¥ ê¶Œì¥)\n",
    "CHECKPOINT = \"/content/drive/MyDrive/M3_final_seg.pth\"\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ(ì••ì¶• í•´ì œ ê²°ê³¼)\n",
    "TR_IMG_DIR = \"/content/ts_sn\"\n",
    "TR_LAB_DIR = \"/content/tl_sn\"\n",
    "VAL_IMG_DIR = \"/content/vs_sn\"\n",
    "VAL_LAB_DIR = \"/content/vl_sn\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLNI4-wOoenr"
   },
   "source": [
    "# 6) ë°ì´í„°ë¡œë” ì¤€ë¹„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_9BUAR8oiel"
   },
   "outputs": [],
   "source": [
    "image_processor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b1-finetuned-ade-512-512\")\n",
    "\n",
    "train_dataset = SegformerDataset(TR_IMG_DIR, TR_LAB_DIR, image_processor)\n",
    "val_dataset   = SegformerDataset(VAL_IMG_DIR, VAL_LAB_DIR, image_processor)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=2, pin_memory=True, persistent_workers=True  # ì›Œì»¤ ìœ ì§€ë¡œ ì´ˆê¸°í™” ë¹„ìš© ì ˆê°\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=2, pin_memory=True, persistent_workers=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB7u01kgol5r"
   },
   "source": [
    "# 7) ëª¨ë¸ ìƒì„± & (ì˜µì…˜) ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygza5HeXoqhz"
   },
   "outputs": [],
   "source": [
    "model = build_segformer_4ch(num_classes=2, device=device)\n",
    "\n",
    "# í‰ê°€ë§Œ ì§„í–‰í•˜ê³  ì‹¶ë‹¤ë©´ TRAIN=Falseë¡œ ë‘ê³  ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n",
    "if not TRAIN and os.path.exists(CHECKPOINT):\n",
    "    model.load_state_dict(torch.load(CHECKPOINT, map_location=device))\n",
    "    model.eval()\n",
    "    print(\"âœ… Loaded checkpoint for evaluation only.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGfZFZxforF0"
   },
   "source": [
    "# 8) í•™ìŠµ ë£¨í”„ & ê²€ì¦(ê³µì‹/ì°¸ê³  ì§€í‘œ ë™ì‹œ ì¶œë ¥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cb97prvxouxZ"
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    scaler = torch.amp.GradScaler('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    print(\"----------- í•™ìŠµ ì‹œì‘ -----------\")\n",
    "    best_iou = -1.0  # ê³µì‹ IoU(sigmoid@0.5) ê¸°ì¤€ìœ¼ë¡œ ìµœê³ ê°’ ì¶”ì \n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} [Train]\"):\n",
    "            pv = batch[\"pixel_values\"].to(device, non_blocking=True)\n",
    "            gt = batch[\"labels\"].to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # AMP: í˜¼í•©ì •ë°€ë¡œ ì—°ì‚° ì†ë„/ë©”ëª¨ë¦¬ ì ˆì•½\n",
    "            with torch.amp.autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                out = model(pixel_values=pv, labels=gt)  # ë‚´ë¶€ CE loss ì‚¬ìš©\n",
    "                loss = out.loss\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / max(1, len(train_loader))\n",
    "\n",
    "        # ì°¸ê³ ìš©: argmax mIoU(ë³´ê³ ì„œìš© í‘œê¸°)\n",
    "        miou_argmax, micro_acc_argmax = evaluate_argmax_miou(model, val_loader, device, num_classes=2)\n",
    "        # ê³µì‹: sigmoid@0.5 Acc/IoU\n",
    "        val_acc, val_iou = evaluate_sigmoid(model, val_loader, device)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{EPOCHS} | Loss: {avg_loss:.4f} | \"\n",
    "              f\"mIoU(argmax): {miou_argmax:.4f} | Acc(sigmoid@0.5): {val_acc:.4f} | IoU(sigmoid@0.5): {val_iou:.4f}\")\n",
    "\n",
    "        # **ê³µì‹ IoU@0.5** ìµœê³ ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "        if val_iou > best_iou:\n",
    "            best_iou = val_iou\n",
    "            torch.save(model.state_dict(), CHECKPOINT)\n",
    "            print(f\"ğŸ† New best (IoU@0.5) saved at {CHECKPOINT}: {best_iou:.4f}\")\n",
    "\n",
    "    print(\"----------- í•™ìŠµ ì¢…ë£Œ -----------\")\n",
    "    print(f\"ìµœê³  IoU@0.5: {best_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1GjtUuOow7I"
   },
   "source": [
    "# 9) ìµœì¢… í‰ê°€(ê³µì‹ ì§€í‘œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0U5sFiZ1o0TI"
   },
   "outputs": [],
   "source": [
    "print(\"----------- ìµœì¢… í‰ê°€ (sigmoid@0.5) -----------\")\n",
    "model.load_state_dict(torch.load(CHECKPOINT, map_location=device))\n",
    "model.eval()\n",
    "val_acc, val_iou = evaluate_sigmoid(model, val_loader, device)\n",
    "print(f\"ğŸ“Š Final Validation â€” Acc: {val_acc:.4f} | IoU@0.5(sigmoid): {val_iou:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
